{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, warnings, random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## -------------------\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "## ------------------- \n",
    "\n",
    "## -------------------\n",
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "## -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "########################### DATA LOAD\n",
    "#################################################################################\n",
    "print('Load Data')\n",
    "train_df = pd.read_csv('../input/train_transaction.csv')\n",
    "test_df = pd.read_csv('../input/test_transaction.csv')\n",
    "test_df['isFraud'] = 0\n",
    "\n",
    "train_identity = pd.read_csv('../input/train_identity.csv')\n",
    "test_identity = pd.read_csv('../input/test_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Base check\n",
    "#################################################################################\n",
    "\n",
    "if LOCAL_TEST:\n",
    "    for df2 in [train_df, test_df, train_identity, test_identity]:\n",
    "        df = reduce_mem_usage(df2)\n",
    "\n",
    "        for col in list(df):\n",
    "            if not df[col].equals(df2[col]):\n",
    "                print('Bad transformation', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 542.35 Mb (69.4% reduction)\n",
      "Mem. usage decreased to 473.07 Mb (68.9% reduction)\n",
      "Mem. usage decreased to 25.86 Mb (42.7% reduction)\n",
      "Mem. usage decreased to 25.44 Mb (42.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "########################### Base Minification\n",
    "#################################################################################\n",
    "\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "test_df  = reduce_mem_usage(test_df)\n",
    "\n",
    "train_identity = reduce_mem_usage(train_identity)\n",
    "test_identity  = reduce_mem_usage(test_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Columns\n",
    "#################################################################################\n",
    "## Main Data\n",
    "# 'TransactionID',\n",
    "# 'isFraud',\n",
    "# 'TransactionDT',\n",
    "# 'TransactionAmt',\n",
    "# 'ProductCD',\n",
    "# 'card1' - 'card6',\n",
    "# 'addr1' - 'addr2',\n",
    "# 'dist1' - 'dist2',\n",
    "# 'P_emaildomain' - 'R_emaildomain',\n",
    "# 'C1' - 'C14'\n",
    "# 'D1' - 'D15'\n",
    "# 'M1' - 'M9'\n",
    "# 'V1' - 'V339'\n",
    "\n",
    "## Identity Data\n",
    "# 'TransactionID'\n",
    "# 'id_01' - 'id_38'\n",
    "# 'DeviceType',\n",
    "# 'DeviceInfo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TransactionID\n",
    "#################################################################################\n",
    "## Possible minification - but it will not give any boost\n",
    "\n",
    "# tID_min = train_df['TransactionID'].min()\n",
    "# train_df['TransactionID'] = train_df['TransactionID'] - tID_min\n",
    "# test_df['TransactionID']  = test_df['TransactionID'] - tID_min\n",
    "# train_identity['TransactionID'] = train_identity['TransactionID'] - tID_min\n",
    "# test_identity['TransactionID']  = test_identity['TransactionID'] - tID_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding card4\n",
      "{'visa': 719649, 'mastercard': 347386, 'american express': 16009, 'discover': 9524}\n",
      "Encoding card6\n",
      "{'debit': 824959, 'credit': 267648, 'debit or credit': 30, 'charge card': 16}\n",
      "Encoding ProductCD\n",
      "{'W': 800657, 'C': 137785, 'R': 73346, 'H': 62397, 'S': 23046}\n"
     ]
    }
   ],
   "source": [
    "########################### card4, card6, ProductCD\n",
    "#################################################################################\n",
    "# Converting Strings to ints(or floats if nan in column) using frequency encoding\n",
    "# We will be able to use these columns as category or as numerical feature\n",
    "\n",
    "for col in ['card4', 'card6', 'ProductCD']:\n",
    "    print('Encoding', col)\n",
    "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    col_encoded = temp_df[col].value_counts().to_dict()   \n",
    "    train_df[col] = train_df[col].map(col_encoded)\n",
    "    test_df[col]  = test_df[col].map(col_encoded)\n",
    "    print(col_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding M4\n",
      "{'M0': 357789, 'M2': 122947, 'M1': 97306}\n"
     ]
    }
   ],
   "source": [
    "########################### M columns\n",
    "#################################################################################\n",
    "# Converting Strings to ints(or floats if nan in column)\n",
    "\n",
    "for col in ['M1','M2','M3','M5','M6','M7','M8','M9']:\n",
    "    train_df[col] = train_df[col].map({'T':1, 'F':0})\n",
    "    test_df[col]  = test_df[col].map({'T':1, 'F':0})\n",
    "\n",
    "for col in ['M4']:\n",
    "    print('Encoding', col)\n",
    "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    col_encoded = temp_df[col].value_counts().to_dict()   \n",
    "    train_df[col] = train_df[col].map(col_encoded)\n",
    "    test_df[col]  = test_df[col].map(col_encoded)\n",
    "    print(col_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Identity columns\n",
    "#################################################################################\n",
    "\n",
    "def minify_identity_df(df):\n",
    "\n",
    "    df['id_12'] = df['id_12'].map({'Found':1, 'NotFound':0})\n",
    "    df['id_15'] = df['id_15'].map({'New':2, 'Found':1, 'Unknown':0})\n",
    "    df['id_16'] = df['id_16'].map({'Found':1, 'NotFound':0})\n",
    "\n",
    "    df['id_23'] = df['id_23'].map({'TRANSPARENT':4, 'IP_PROXY':3, 'IP_PROXY:ANONYMOUS':2, 'IP_PROXY:HIDDEN':1})\n",
    "\n",
    "    df['id_27'] = df['id_27'].map({'Found':1, 'NotFound':0})\n",
    "    df['id_28'] = df['id_28'].map({'New':2, 'Found':1})\n",
    "\n",
    "    df['id_29'] = df['id_29'].map({'Found':1, 'NotFound':0})\n",
    "\n",
    "    df['id_35'] = df['id_35'].map({'T':1, 'F':0})\n",
    "    df['id_36'] = df['id_36'].map({'T':1, 'F':0})\n",
    "    df['id_37'] = df['id_37'].map({'T':1, 'F':0})\n",
    "    df['id_38'] = df['id_38'].map({'T':1, 'F':0})\n",
    "\n",
    "    df['id_34'] = df['id_34'].fillna(':0')\n",
    "    df['id_34'] = df['id_34'].apply(lambda x: x.split(':')[1]).astype(np.int8)\n",
    "    df['id_34'] = np.where(df['id_34']==0, np.nan, df['id_34'])\n",
    "    \n",
    "    df['id_33'] = df['id_33'].fillna('0x0')\n",
    "    df['id_33_0'] = df['id_33'].apply(lambda x: x.split('x')[0]).astype(int)\n",
    "    df['id_33_1'] = df['id_33'].apply(lambda x: x.split('x')[1]).astype(int)\n",
    "    df['id_33'] = np.where(df['id_33']=='0x0', np.nan, df['id_33'])\n",
    "\n",
    "    df['DeviceType'].map({'desktop':1, 'mobile':0})\n",
    "    return df\n",
    "\n",
    "train_identity = minify_identity_df(train_identity)\n",
    "test_identity = minify_identity_df(test_identity)\n",
    "\n",
    "for col in ['id_33']:\n",
    "    train_identity[col] = train_identity[col].fillna('unseen_before_label')\n",
    "    test_identity[col]  = test_identity[col].fillna('unseen_before_label')\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train_identity[col])+list(test_identity[col]))\n",
    "    train_identity[col] = le.transform(train_identity[col])\n",
    "    test_identity[col]  = le.transform(test_identity[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 506.30 Mb (6.6% reduction)\n",
      "Mem. usage decreased to 442.14 Mb (6.5% reduction)\n",
      "Mem. usage decreased to 15.54 Mb (44.6% reduction)\n",
      "Mem. usage decreased to 15.29 Mb (44.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "########################### Final Minification\n",
    "#################################################################################\n",
    "\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "test_df  = reduce_mem_usage(test_df)\n",
    "\n",
    "train_identity = reduce_mem_usage(train_identity)\n",
    "test_identity  = reduce_mem_usage(test_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "\n",
    "train_df.to_pickle('../input/ieee-data-minification/train_transaction.pkl')\n",
    "test_df.to_pickle('../input/ieee-data-minification/test_transaction.pkl')\n",
    "\n",
    "train_identity.to_pickle('../input/ieee-data-minification/train_identity.pkl')\n",
    "test_identity.to_pickle('../input/ieee-data-minification/test_identity.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
